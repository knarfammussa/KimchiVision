{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194c3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import math\n",
    "from easydict import EasyDict as edict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b5d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtr modules\n",
    "from mtr.datasets import build_dataloader\n",
    "from mtr.config import cfg, cfg_from_yaml_file\n",
    "from mtr.utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e4ebf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1013d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_from_yaml_file(\"/code/jjiang23/csc587/KimchiVision/cfg/kimchiConfig.yaml\", cfg)\n",
    "logger = common_utils.create_logger(\"/files/waymo/log.txt\", rank=0)\n",
    "args = edict({\n",
    "    \"batch_size\": 64,\n",
    "    \"workers\": 32,\n",
    "    \"merge_all_iters_to_one_epoch\": False,\n",
    "    \"epochs\": 5,\n",
    "    \"add_worker_init_fn\": False,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2edafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    batch_size=args.batch_size,\n",
    "    dist=False, workers=args.workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "    total_epochs=args.epochs,\n",
    "    add_worker_init_fn=args.add_worker_init_fn,\n",
    ")\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=False, workers=args.workers, logger=logger, training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "class MotionLSTM(nn.Module):\n",
    "    '''\n",
    "    Input: \n",
    "    - obj_trajs (num_center_objects(batch_size), num_objects, num_timestamps, num_attrs)\n",
    "    - obj_trajs_mask (num_center_objects(batch_size), num_objects, num_timestamps)\n",
    "    - map_polylines (num_center_objects(batch_size),num_polylines, num_points_each_polyline, 7)\n",
    "    - map_polylines_mask (num_center_objects(batch_size),num_polylines(4000), num_points_each_polyline(20))\n",
    "    - track index (num_center_objects(batch_size), )\n",
    "\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                input_dim=29 + 4000*20*7,  # Based on MTR dataset obj_trajs feature dimension\n",
    "                # Map polylines encoder parameters\n",
    "                map_polyline_encoder_output_dim=256,  # Hidden dimension for the map polyline encoder\n",
    "                map_polyline_encoder_input_dim= 4000*20*7,  # Input dimension for the map polyline encoder\n",
    "                # Encoder and decoder parameters for object trajectories\n",
    "                encoder_hidden_dim=256,\n",
    "                encoder_output_dim=256,  # Output dimension of the encoder\n",
    "\n",
    "                decoder_hidden_dim=256,\n",
    "                decoder_output_dim=256,  # Output dimension of the decoder\n",
    "                # LSTM parameters\n",
    "                lstm_hidden_dim=256,\n",
    "                lstm_num_layers=2,\n",
    "                # attention parameters\n",
    "                # mode _predictor parameters\n",
    "                mode_predictor_hidden_dim=256,\n",
    "                mode_predictor_output_dim=256,  # Output dimension of the mode predictor\n",
    "                # trajectory decoder parameters\n",
    "                trajectory_decoder_hidden_dim=256,\n",
    "                trajectory_decoder_output_dim=256,  # Output dimension of the trajectory decoder\n",
    "                num_modes=6,  # Number of prediction modes\n",
    "                future_steps=80,  # Number of future timesteps to predict\n",
    "                dropout=0.1):\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.num_modes = num_modes\n",
    "        self.future_steps = future_steps\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # # Map polylines encoder\n",
    "        # self.map_polyline_encoder = nn.Sequential(\n",
    "        #     nn.Linear(map_polyline_encoder_input_dim, 512),  \n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(encoder_hidden_dim, encoder_output_dim)\n",
    "        # )\n",
    "\n",
    "        # Feature encoder for input trajectories\n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoder_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(encoder_hidden_dim, encoder_output_dim)\n",
    "        )\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=encoder_output_dim,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=lstm_num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Multi-modal prediction heads\n",
    "        self.mode_predictor = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden_dim, mode_predictor_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mode_predictor_output_dim, num_modes)\n",
    "        )\n",
    "        \n",
    "        # Trajectory decoder for each mode\n",
    "        self.traj_decoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(lstm_hidden_dim, trajectory_decoder_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(trajectory_decoder_hidden_dim, trajectory_decoder_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(trajectory_decoder_output_dim, future_steps * 4)  # x, y, vx, vy for each timestep\n",
    "            ) for _ in range(num_modes)\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism for object interactions\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=lstm_hidden_dim,\n",
    "            num_heads=8,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "    def forward(self,):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48068056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
