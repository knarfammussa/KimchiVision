{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1cbcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import math\n",
    "from easydict import EasyDict as edict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436ffd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtr modules\n",
    "from mtr.datasets import build_dataloader\n",
    "from mtr.config import cfg, cfg_from_yaml_file\n",
    "from mtr.utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd44e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_from_yaml_file(\"/code/jjiang23/csc587/KimchiVision/cfg/kimchiConfig.yaml\", cfg)\n",
    "logger = common_utils.create_logger(\"/files/waymo/damon_log.txt\", rank=0)\n",
    "args = edict({\n",
    "    \"batch_size\": 1,\n",
    "    \"workers\": 32,\n",
    "    \"merge_all_iters_to_one_epoch\": False,\n",
    "    \"epochs\": 5,\n",
    "    \"add_worker_init_fn\": False,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3d06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 14:42:29,976   INFO  Start to load infos from /files/waymo/code/MTR/data/waymo/processed_scenarios_training_infos.pkl\n",
      "2025-06-08 14:42:36,327   INFO  Total scenes before filters: 243401\n",
      "2025-06-08 14:42:43,140   INFO  Total scenes after filter_info_by_object_type: 243401\n",
      "2025-06-08 14:42:43,150   INFO  Total scenes after filters: 243401\n",
      "2025-06-08 14:42:43,152   INFO  Start to load infos from /files/waymo/code/MTR/data/waymo/processed_scenarios_val_infos.pkl\n",
      "2025-06-08 14:42:44,973   INFO  Total scenes before filters: 22089\n",
      "2025-06-08 14:42:45,617   INFO  Total scenes after filter_info_by_object_type: 22089\n",
      "2025-06-08 14:42:45,622   INFO  Total scenes after filters: 22089\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    batch_size=args.batch_size,\n",
    "    dist=False, workers=args.workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "    total_epochs=args.epochs,\n",
    "    add_worker_init_fn=args.add_worker_init_fn,\n",
    ")\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=False, workers=args.workers, logger=logger, training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "379ed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.simple_lstm import MotionLSTM\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MotionLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6514837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c94fd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scenario_id', 'obj_trajs', 'obj_trajs_mask', 'track_index_to_predict', 'obj_trajs_pos', 'obj_trajs_last_pos', 'obj_types', 'obj_ids', 'center_objects_world', 'center_objects_id', 'center_objects_type', 'obj_trajs_future_state', 'obj_trajs_future_mask', 'center_gt_trajs', 'center_gt_trajs_mask', 'center_gt_final_valid_idx', 'center_gt_trajs_src', 'map_polylines', 'map_polylines_mask', 'map_polylines_center', 'static_map_polylines', 'static_map_polylines_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b72d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = batch[\"input_dict\"]\n",
    "obj_trajs = input[\"obj_trajs\"]\n",
    "obj_pos = input[\"obj_trajs_pos\"]\n",
    "obj_last_pos = input[\"obj_trajs_last_pos\"]\n",
    "obj_type = input[\"obj_types\"] # car, bicycycle, pedestrian\n",
    "obj_trajs_mask = input['obj_trajs_mask']\n",
    "obj_of_interest = input['track_index_to_predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c0eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_center_objects, num_objects, num_timestamps, num_attrs = obj_trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162b4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_map_polylines=input[\"static_map_polylines\"].to('cuda')  # (batch_size, num_polylines, num_points_each_polyline, 7)\n",
    "static_map_polylines_mask=input[\"static_map_polylines_mask\"].to('cuda') # (batch_size, num_polylines, num_points_each_polyline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c107aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: scenario_id, Val: (1,)\n",
      "Key: obj_trajs, Val: torch.Size([1, 41, 11, 29])\n",
      "Key: obj_trajs_mask, Val: torch.Size([1, 41, 11])\n",
      "Key: track_index_to_predict, Val: torch.Size([1])\n",
      "Key: obj_trajs_pos, Val: torch.Size([1, 41, 11, 3])\n",
      "Key: obj_trajs_last_pos, Val: torch.Size([1, 41, 3])\n",
      "Key: obj_types, Val: (41,)\n",
      "Key: obj_ids, Val: (41,)\n",
      "Key: center_objects_world, Val: torch.Size([1, 10])\n",
      "Key: center_objects_id, Val: (1,)\n",
      "Key: center_objects_type, Val: (1,)\n",
      "Key: obj_trajs_future_state, Val: torch.Size([1, 41, 80, 4])\n",
      "Key: obj_trajs_future_mask, Val: torch.Size([1, 41, 80])\n",
      "Key: center_gt_trajs, Val: torch.Size([1, 80, 4])\n",
      "Key: center_gt_trajs_mask, Val: torch.Size([1, 80])\n",
      "Key: center_gt_final_valid_idx, Val: torch.Size([1])\n",
      "Key: center_gt_trajs_src, Val: torch.Size([1, 91, 10])\n",
      "Key: map_polylines, Val: torch.Size([1, 742, 20, 9])\n",
      "Key: map_polylines_mask, Val: torch.Size([1, 742, 20])\n",
      "Key: map_polylines_center, Val: torch.Size([1, 742, 3])\n",
      "Key: static_map_polylines, Val: torch.Size([1, 4000, 20, 7])\n",
      "Key: static_map_polylines_mask, Val: torch.Size([1, 4000, 20])\n"
     ]
    }
   ],
   "source": [
    "model._print_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05b495dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79., 79., 79., 79.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_dict\"][\"center_gt_final_valid_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3bbf9d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(obj_trajs_mask[0, 0, :])[-1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77430603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.loss import MotionLoss\n",
    "\n",
    "criterion = MotionLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "accf61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores, pred_trajs = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2986f8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c7ea83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14007.6367, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d480306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71926b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input['center_gt_trajs_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "class MotionLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function for trajectory prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 regression_loss_weight=1.0,\n",
    "                 classification_loss_weight=1.0,\n",
    "                 future_loss_weight=1.0):\n",
    "        super(MotionLoss, self).__init__()\n",
    "        self.reg_weight = regression_loss_weight\n",
    "        self.cls_weight = classification_loss_weight\n",
    "        self.future_weight = future_loss_weight\n",
    "    \n",
    "    def forward(self, pred_scores, pred_trajs, batch_dict):\n",
    "        \"\"\"\n",
    "        Compute loss\n",
    "        \n",
    "        Args:\n",
    "            pred_scores: (batch_size, num_modes)\n",
    "            pred_trajs: (batch_size, num_modes, future_steps, 4)\n",
    "            batch_dict: Contains ground truth data\n",
    "        \n",
    "        Returns:\n",
    "            loss_dict: Dictionary containing different loss components\n",
    "        \"\"\"\n",
    "        center_gt_trajs = batch_dict['input_dict']['center_gt_trajs'].to('cuda')  # (batch_size, future_steps, 4)\n",
    "        center_gt_trajs_mask = batch_dict['input_dict']['center_gt_trajs_mask'].to('cuda')  # (batch_size, future_steps)\n",
    "        \n",
    "        batch_size, num_modes, future_steps, _ = pred_trajs.shape\n",
    "        \n",
    "        # Compute trajectory regression loss for each mode\n",
    "        gt_trajs_expanded = center_gt_trajs.unsqueeze(1).expand(-1, num_modes, -1, -1)\n",
    "        gt_mask_expanded = center_gt_trajs_mask.unsqueeze(1).expand(-1, num_modes, -1)\n",
    "        \n",
    "        # L2 loss for position (x, y)\n",
    "        pos_loss = F.mse_loss(\n",
    "            pred_trajs[:, :, :, :2] * gt_mask_expanded.unsqueeze(-1),\n",
    "            gt_trajs_expanded[:, :, :, :2] * gt_mask_expanded.unsqueeze(-1),\n",
    "            reduction='none'\n",
    "        ).sum(dim=-1)  # (batch_size, num_modes, future_steps)\n",
    "        \n",
    "        # L2 loss for velocity (vx, vy)\n",
    "        vel_loss = F.mse_loss(\n",
    "            pred_trajs[:, :, :, 2:4] * gt_mask_expanded.unsqueeze(-1),\n",
    "            gt_trajs_expanded[:, :, :, 2:4] * gt_mask_expanded.unsqueeze(-1),\n",
    "            reduction='none'\n",
    "        ).sum(dim=-1)  # (batch_size, num_modes, future_steps)\n",
    "        \n",
    "        # Weighted loss over time (give more weight to near future)\n",
    "        time_weights = torch.exp(-0.1 * torch.arange(future_steps, device=pred_trajs.device))\n",
    "        time_weights = time_weights.view(1, 1, -1)\n",
    "        \n",
    "        pos_loss = (pos_loss * time_weights * gt_mask_expanded).sum(dim=-1)  # (batch_size, num_modes)\n",
    "        vel_loss = (vel_loss * time_weights * gt_mask_expanded).sum(dim=-1)  # (batch_size, num_modes)\n",
    "        \n",
    "        # Find best mode for each sample\n",
    "        total_traj_loss = pos_loss + vel_loss  # (batch_size, num_modes)\n",
    "        best_mode_indices = torch.argmin(total_traj_loss, dim=1)  # (batch_size,)\n",
    "        \n",
    "        # Regression loss (best mode)\n",
    "        best_pos_loss = pos_loss[torch.arange(batch_size), best_mode_indices].mean()\n",
    "        best_vel_loss = vel_loss[torch.arange(batch_size), best_mode_indices].mean()\n",
    "        regression_loss = best_pos_loss + best_vel_loss\n",
    "        \n",
    "        # Classification loss (encourage higher confidence for best mode)\n",
    "        target_scores = torch.zeros_like(pred_scores)\n",
    "        target_scores[torch.arange(batch_size), best_mode_indices] = 1.0\n",
    "        classification_loss = F.cross_entropy(pred_scores, target_scores)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (self.reg_weight * regression_loss + \n",
    "                     self.cls_weight * classification_loss)\n",
    "        \n",
    "        loss_dict = {\n",
    "            'total_loss': total_loss,\n",
    "            'regression_loss': regression_loss,\n",
    "            'classification_loss': classification_loss,\n",
    "            'pos_loss': best_pos_loss,\n",
    "            'vel_loss': best_vel_loss\n",
    "        }\n",
    "        \n",
    "        return loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.loss import MotionLoss\n",
    "\n",
    "#train loop\n",
    "def train_model(model, train_dataloader, val_dataloader, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Training loop for the LSTM model\n",
    "    \"\"\"\n",
    "    assert torch.cuda.is_available(), \"CUDA is not available. Please check your PyTorch installation.\"\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = MotionLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(train_dataloader):\n",
    "            # Move data to device\n",
    "            for key, value in batch_dict.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    batch_dict[key] = value.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_scores, pred_trajs = model(batch_dict)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(pred_scores, pred_trajs, batch_dict)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_dict in val_dataloader:\n",
    "                # Move data to device\n",
    "                for key, value in batch_dict.items():\n",
    "                    if isinstance(value, torch.Tensor):\n",
    "                        batch_dict[key] = value.to(device)\n",
    "                \n",
    "                pred_scores, pred_trajs = model(batch_dict)\n",
    "                loss_dict = criterion(pred_scores, pred_trajs, batch_dict)\n",
    "                val_losses.append(loss_dict['total_loss'].item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), '/code/jjiang23/csc587/KimchiVision/best_motion_lstm.pth')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83dd4c9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MotionLSTM()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dlin42/KimchiVision/lstm/train_util.py:17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     16\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mnum_epochs)\n\u001b[0;32m---> 17\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mMotionLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m/home/dlin42/KimchiVision/lstm/loss.py:19\u001b[0m, in \u001b[0;36mMotionLoss.__init__\u001b[0;34m(self, regression_loss_weight, classification_loss_weight, future_loss_weight, gamma)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     14\u001b[0m              regression_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     15\u001b[0m              classification_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     16\u001b[0m              future_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     17\u001b[0m              gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.025\u001b[39m \u001b[38;5;66;03m# this gamma is chosen because at timestep 80, the time weight won't be zero\u001b[39;00m\n\u001b[1;32m     18\u001b[0m             ):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMotionLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_weight \u001b[38;5;241m=\u001b[39m regression_loss_weight\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_weight \u001b[38;5;241m=\u001b[39m classification_loss_weight\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "from lstm.train_util import train_model\n",
    "from lstm.simple_lstm import MotionLSTM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MotionLSTM().to(device)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, train_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
