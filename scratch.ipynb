{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1cbcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import math\n",
    "from easydict import EasyDict as edict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5f88e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "lstm = nn.LSTM(input_size=3, hidden_size=3, num_layers=1, batch_first=True)\n",
    "\n",
    "x = torch.randn(2, 5, 3)  # random input: batch of 2 sequences, each length 5, features 3\n",
    "\n",
    "output, (h_n, c_n) = lstm(x)\n",
    "print(\"Output shape:\", output.shape)  # Output shape: (2, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436ffd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtr modules\n",
    "from mtr.datasets import build_dataloader\n",
    "from mtr.config import cfg, cfg_from_yaml_file\n",
    "from mtr.utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd44e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_from_yaml_file(\"/code/jjiang23/csc587/KimchiVision/cfg/kimchiConfig.yaml\", cfg)\n",
    "logger = common_utils.create_logger(\"/files/waymo/damon_log.txt\", rank=0)\n",
    "args = edict({\n",
    "    \"batch_size\": 8,\n",
    "    \"workers\": 32,\n",
    "    \"merge_all_iters_to_one_epoch\": False,\n",
    "    \"epochs\": 5,\n",
    "    \"add_worker_init_fn\": False,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3d06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 22:02:13,752   INFO  Start to load infos from /files/waymo/code/MTR/data/waymo/processed_scenarios_training_infos.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 22:02:19,582   INFO  Total scenes before filters: 243401\n",
      "2025-06-08 22:02:26,791   INFO  Total scenes after filter_info_by_object_type: 243401\n",
      "2025-06-08 22:02:26,816   INFO  Total scenes after filters: 243401\n",
      "2025-06-08 22:02:26,997   INFO  Start to load infos from /files/waymo/code/MTR/data/waymo/processed_scenarios_val_infos.pkl\n",
      "2025-06-08 22:02:28,708   INFO  Total scenes before filters: 22089\n",
      "2025-06-08 22:02:29,454   INFO  Total scenes after filter_info_by_object_type: 22089\n",
      "2025-06-08 22:02:29,456   INFO  Total scenes after filters: 22089\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    batch_size=args.batch_size,\n",
    "    dist=False, workers=args.workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "    total_epochs=args.epochs,\n",
    "    add_worker_init_fn=args.add_worker_init_fn,\n",
    ")\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=False, workers=args.workers, logger=logger, training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379ed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.train_util import train_model\n",
    "from lstm.lstm import MotionLSTM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MotionLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6514837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = batch[\"input_dict\"]\n",
    "obj_trajs = input[\"obj_trajs\"]\n",
    "obj_pos = input[\"obj_trajs_pos\"]\n",
    "obj_last_pos = input[\"obj_trajs_last_pos\"]\n",
    "obj_type = input[\"obj_types\"] # car, bicycycle, pedestrian\n",
    "obj_trajs_mask = input['obj_trajs_mask']\n",
    "obj_of_interest = input['track_index_to_predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_center_objects, num_objects, num_timestamps, num_attrs = obj_trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_map_polylines=input[\"static_map_polylines\"].to('cuda')  # (batch_size, num_polylines, num_points_each_polyline, 7)\n",
    "static_map_polylines_mask=input[\"static_map_polylines_mask\"].to('cuda') # (batch_size, num_polylines, num_points_each_polyline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c107aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model._print_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b495dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_dict\"][\"center_gt_final_valid_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(obj_trajs_mask[0, 0, :])[-1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77430603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.loss import MotionLoss\n",
    "\n",
    "criterion = MotionLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_dict\"][\"obj_trajs_mask\"][0, 0, :][-1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accf61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(2, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(2, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(5, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(3, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(2, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(9, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(8, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(6, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "9 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "10 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "11 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "12 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "13 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "14 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "15 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "16 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "17 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "18 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "19 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "20 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "21 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "22 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "23 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "24 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "25 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "26 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "27 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "28 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "29 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "0 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "1 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "2 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "3 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "4 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "5 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "6 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "7 torch.Size([30, 96, 11]) tensor(11, device='cuda:0')\n",
      "8 torch.Size([30, 96, 11]) tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_scores, pred_trajs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/waymo/miniconda3/envs/lstm/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/waymo/miniconda3/envs/lstm/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/dlin42/KimchiVision/lstm/lstm.py:191\u001b[0m, in \u001b[0;36mMotionLSTM.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(b, obj_trajs_mask\u001b[38;5;241m.\u001b[39mshape, obj_trajs_mask[b, obj_idx, :]\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m--> 191\u001b[0m     last_valid_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_trajs_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    192\u001b[0m     last_outputs\u001b[38;5;241m.\u001b[39mappend(lstm_out[b, last_valid_idx, :])\n\u001b[1;32m    194\u001b[0m last_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(last_outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (batch_size, hidden_dim)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "pred_scores, pred_trajs = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2986f8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ea83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d480306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71926b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input['center_gt_trajs_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "class MotionLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function for trajectory prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 regression_loss_weight=1.0,\n",
    "                 classification_loss_weight=1.0,\n",
    "                 future_loss_weight=1.0):\n",
    "        super(MotionLoss, self).__init__()\n",
    "        self.reg_weight = regression_loss_weight\n",
    "        self.cls_weight = classification_loss_weight\n",
    "        self.future_weight = future_loss_weight\n",
    "    \n",
    "    def forward(self, pred_scores, pred_trajs, batch_dict):\n",
    "        \"\"\"\n",
    "        Compute loss\n",
    "        \n",
    "        Args:\n",
    "            pred_scores: (batch_size, num_modes)\n",
    "            pred_trajs: (batch_size, num_modes, future_steps, 4)\n",
    "            batch_dict: Contains ground truth data\n",
    "        \n",
    "        Returns:\n",
    "            loss_dict: Dictionary containing different loss components\n",
    "        \"\"\"\n",
    "        center_gt_trajs = batch_dict['input_dict']['center_gt_trajs'].to('cuda')  # (batch_size, future_steps, 4)\n",
    "        center_gt_trajs_mask = batch_dict['input_dict']['center_gt_trajs_mask'].to('cuda')  # (batch_size, future_steps)\n",
    "        \n",
    "        batch_size, num_modes, future_steps, _ = pred_trajs.shape\n",
    "        \n",
    "        # Compute trajectory regression loss for each mode\n",
    "        gt_trajs_expanded = center_gt_trajs.unsqueeze(1).expand(-1, num_modes, -1, -1)\n",
    "        gt_mask_expanded = center_gt_trajs_mask.unsqueeze(1).expand(-1, num_modes, -1)\n",
    "        \n",
    "        # L2 loss for position (x, y)\n",
    "        pos_loss = F.mse_loss(\n",
    "            pred_trajs[:, :, :, :2] * gt_mask_expanded.unsqueeze(-1),\n",
    "            gt_trajs_expanded[:, :, :, :2] * gt_mask_expanded.unsqueeze(-1),\n",
    "            reduction='none'\n",
    "        ).sum(dim=-1)  # (batch_size, num_modes, future_steps)\n",
    "        \n",
    "        # L2 loss for velocity (vx, vy)\n",
    "        vel_loss = F.mse_loss(\n",
    "            pred_trajs[:, :, :, 2:4] * gt_mask_expanded.unsqueeze(-1),\n",
    "            gt_trajs_expanded[:, :, :, 2:4] * gt_mask_expanded.unsqueeze(-1),\n",
    "            reduction='none'\n",
    "        ).sum(dim=-1)  # (batch_size, num_modes, future_steps)\n",
    "        \n",
    "        # Weighted loss over time (give more weight to near future)\n",
    "        time_weights = torch.exp(-0.1 * torch.arange(future_steps, device=pred_trajs.device))\n",
    "        time_weights = time_weights.view(1, 1, -1)\n",
    "        \n",
    "        pos_loss = (pos_loss * time_weights * gt_mask_expanded).sum(dim=-1)  # (batch_size, num_modes)\n",
    "        vel_loss = (vel_loss * time_weights * gt_mask_expanded).sum(dim=-1)  # (batch_size, num_modes)\n",
    "        \n",
    "        # Find best mode for each sample\n",
    "        total_traj_loss = pos_loss + vel_loss  # (batch_size, num_modes)\n",
    "        best_mode_indices = torch.argmin(total_traj_loss, dim=1)  # (batch_size,)\n",
    "        \n",
    "        # Regression loss (best mode)\n",
    "        best_pos_loss = pos_loss[torch.arange(batch_size), best_mode_indices].mean()\n",
    "        best_vel_loss = vel_loss[torch.arange(batch_size), best_mode_indices].mean()\n",
    "        regression_loss = best_pos_loss + best_vel_loss\n",
    "        \n",
    "        # Classification loss (encourage higher confidence for best mode)\n",
    "        target_scores = torch.zeros_like(pred_scores)\n",
    "        target_scores[torch.arange(batch_size), best_mode_indices] = 1.0\n",
    "        classification_loss = F.cross_entropy(pred_scores, target_scores)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (self.reg_weight * regression_loss + \n",
    "                     self.cls_weight * classification_loss)\n",
    "        \n",
    "        loss_dict = {\n",
    "            'total_loss': total_loss,\n",
    "            'regression_loss': regression_loss,\n",
    "            'classification_loss': classification_loss,\n",
    "            'pos_loss': best_pos_loss,\n",
    "            'vel_loss': best_vel_loss\n",
    "        }\n",
    "        \n",
    "        return loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.loss import MotionLoss\n",
    "\n",
    "#train loop\n",
    "def train_model(model, train_dataloader, val_dataloader, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Training loop for the LSTM model\n",
    "    \"\"\"\n",
    "    assert torch.cuda.is_available(), \"CUDA is not available. Please check your PyTorch installation.\"\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = MotionLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(train_dataloader):\n",
    "            # Move data to device\n",
    "            for key, value in batch_dict.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    batch_dict[key] = value.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_scores, pred_trajs = model(batch_dict)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(pred_scores, pred_trajs, batch_dict)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_dict in val_dataloader:\n",
    "                # Move data to device\n",
    "                for key, value in batch_dict.items():\n",
    "                    if isinstance(value, torch.Tensor):\n",
    "                        batch_dict[key] = value.to(device)\n",
    "                \n",
    "                pred_scores, pred_trajs = model(batch_dict)\n",
    "                loss_dict = criterion(pred_scores, pred_trajs, batch_dict)\n",
    "                val_losses.append(loss_dict['total_loss'].item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), '/code/jjiang23/csc587/KimchiVision/best_motion_lstm.pth')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm.train_util import train_model\n",
    "from lstm.lstm import MotionLSTM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MotionLSTM().to(device)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, train_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
